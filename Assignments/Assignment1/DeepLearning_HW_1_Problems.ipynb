{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.a (5%) Find the eigenvalues and a basis consisting of eigenvectors of \n",
    "\n",
    "\n",
    "$$A = \\begin{bmatrix}\n",
    "    1  & 1 & -1  \\\\\n",
    "    -3  & -3 & 1  \\\\\n",
    "    -3  & -3 & 1  \\\\\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.b (5%) Find the coordinates of the vector with respect to the basis of eigenvectors found at problem 1.\n",
    "\n",
    "$$v = \\begin{bmatrix}\n",
    "     0  \\\\\n",
    "     1  \\\\\n",
    "     0  \\\\\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.c (5%) Calculate  $A^{2019}v$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[                   0, -4771718345474059377,\n",
       "                            0],\n",
       "        [                   0,  4571248787882505707,\n",
       "                            0],\n",
       "        [                   0,  4571248787882505707,\n",
       "                            0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.matrix([[1, 1, -1], [-3, -3, 1], [-3, -3, 1]])\n",
    "v = np.matrix([[0,1,0]])\n",
    "pow = (np.abs(a) ** 2019) * np.sign(a)\n",
    "np.multiply(pow,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (10%) A typical page in a book contains one typo per page.  What is the probability that there are exactly 8 typos in a given 10-page chapter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Poisson distribution. Since the expected number of typos on one page is 1, the expected number of typos in 10 pages is 10. Hence, we use the Poisson formula with Î» = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. (10%) Suppose  that  every  page  in  the  chapter  contains  exactly  3000  characters,  and there is still an average of one typo per page.  What is the probability that there are exactly 8 typos in the 10-page chapter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we use a binomial distribution, where a typo counts as a success. The probability of success is 1 ; we have 30000 trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.(10%) Draw an ANN to implment $A \\bigoplus B$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create the network with random weights and random biases. Second, we set the activation of the two input nodes from the columns 'a' and 'b' in the table, and run the network forward. Third, we compare the output produced by the network to the desired output (in the third column of the truth table), and calculate the difference between the actual output and the desired output. This difference is the error signal. Fourth, we change the weights of the connections that connect to the output node, and the bias of the output node. Fifth, we pass the error back to the hidden layer, and change the biases and weights of those connections. Then the cycle repeats with new inputs and new outputs. The network trains until the average error (calculated over all four rows in the truth table) approaches zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (20%) Train a deep MLP on the MNIST dataset and see if how much accuracy you can ge?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. (20%) For MNIST, can you design a new model based on CNN to retrain? How much accuracy get now? If you have GPU, try to play with those model paramters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. (15%) Given iris.csv data set. Using NN with Cross-Validation to Classify. Report Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris.data.shape, iris.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.4, random_state=0)\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "\n",
    "X_test.shape, y_test.shape\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",
    "scores     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96658312, 1.        , 0.96658312, 0.96658312, 1.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "scores = cross_val_score(\n",
    "    clf, iris.data, iris.target, cv=5, scoring='f1_macro')\n",
    "scores   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.97777778, 1.        , 0.95555556, 1.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "n_samples = iris.data.shape[0]\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "cross_val_score(clf, iris.data, iris.target, cv=cv)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.97333333])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_cv_2folds(X):\n",
    "    n = X.shape[0]\n",
    "    i = 1\n",
    "    while i <= 2:\n",
    "        idx = np.arange(n * (i - 1) / 2, n * i / 2, dtype=int)\n",
    "        yield idx, idx\n",
    "        i += 1\n",
    "\n",
    "custom_cv = custom_cv_2folds(iris.data)\n",
    "cross_val_score(clf, iris.data, iris.target, cv=custom_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.4, random_state=0)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_transformed = scaler.transform(X_train)\n",
    "clf = svm.SVC(C=1).fit(X_train_transformed, y_train)\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "clf.score(X_test_transformed, y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.93333333, 0.95555556, 0.93333333, 0.97777778])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), svm.SVC(C=1))\n",
    "cross_val_score(clf, iris.data, iris.target, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=0)\n",
    "scores = cross_validate(clf, iris.data, iris.target, scoring=scoring,\n",
    "                        cv=5, return_train_score=False)\n",
    "sorted(scores.keys())\n",
    "\n",
    "scores['test_recall_macro']     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['estimator', 'fit_time', 'score_time', 'test_score', 'train_score']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(clf, iris.data, iris.target,\n",
    "                        scoring='precision_macro', cv=5,\n",
    "                        return_estimator=True)\n",
    "sorted(scores.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "from random import seed\n",
    "from random import random\n",
    "\n",
    "# Initialize a network\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "\tnetwork = list()\n",
    "\thidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
    "\tnetwork.append(hidden_layer)\n",
    "\toutput_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
    "\tnetwork.append(output_layer)\n",
    "\treturn network\n",
    "\n",
    "# Calculate neuron activation for an input\n",
    "def activate(weights, inputs):\n",
    "\tactivation = weights[-1]\n",
    "\tfor i in range(len(weights)-1):\n",
    "\t\tactivation += weights[i] * inputs[i]\n",
    "\treturn activation\n",
    "\n",
    "# Transfer neuron activation\n",
    "def transfer(activation):\n",
    "    return (2/(1+exp(-2*activation))) - 1\n",
    "\n",
    "# Forward propagate input to a network output\n",
    "def forward_propagate(network, row):\n",
    "\tinputs = row\n",
    "\tfor layer in network:\n",
    "\t\tnew_inputs = []\n",
    "\t\tfor neuron in layer:\n",
    "\t\t\tactivation = activate(neuron['weights'], inputs)\n",
    "\t\t\tneuron['output'] = transfer(activation)\n",
    "\t\t\tnew_inputs.append(neuron['output'])\n",
    "\t\tinputs = new_inputs\n",
    "\treturn inputs\n",
    "\n",
    "# Calculate the derivative of an neuron output\n",
    "def transfer_derivative(output):\n",
    "\treturn 1 - (output*output)\n",
    "\n",
    "# Backpropagate error and store in neurons\n",
    "def backward_propagate_error(network, expected):\n",
    "\tfor i in reversed(range(len(network))):\n",
    "\t\tlayer = network[i]\n",
    "\t\terrors = list()\n",
    "\t\tif i != len(network)-1:\n",
    "\t\t\tfor j in range(len(layer)):\n",
    "\t\t\t\terror = 0.0\n",
    "\t\t\t\tfor neuron in network[i + 1]:\n",
    "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
    "\t\t\t\terrors.append(error)\n",
    "\t\telse:\n",
    "\t\t\tfor j in range(len(layer)):\n",
    "\t\t\t\tneuron = layer[j]\n",
    "\t\t\t\terrors.append((expected[j] - neuron['output']))\n",
    "\t\tfor j in range(len(layer)):\n",
    "\t\t\tneuron = layer[j]\n",
    "\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
    "\n",
    "# Update network weights with error\n",
    "def update_weights(network, row, l_rate):\n",
    "\tfor i in range(len(network)):\n",
    "\t\tinputs = row[:-1]\n",
    "\t\tif i != 0:\n",
    "\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "\t\tfor neuron in network[i]:\n",
    "\t\t\tfor j in range(len(inputs)):\n",
    "\t\t\t\tneuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
    "\t\t\tneuron['weights'][-1] += l_rate * neuron['delta']\n",
    "\n",
    "# Train a network for a fixed number of epochs\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "\tfor epoch in range(n_epoch):\n",
    "\t\tsum_error = 0\n",
    "\t\tfor row in train:\n",
    "\t\t\toutputs = forward_propagate(network, row)\n",
    "\t\t\texpected = [0 for i in range(n_outputs)]\n",
    "\t\t\texpected[row[0]] = 1\n",
    "\t\t\tsum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "\t\t\tbackward_propagate_error(network, expected)\n",
    "\t\t\tupdate_weights(network, row, l_rate)\n",
    "\t\tprint('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.500, error=20.001\n",
      ">epoch=1, lrate=0.500, error=6.009\n",
      ">epoch=2, lrate=0.500, error=7.245\n",
      ">epoch=3, lrate=0.500, error=7.490\n",
      ">epoch=4, lrate=0.500, error=7.579\n",
      ">epoch=5, lrate=0.500, error=7.604\n",
      ">epoch=6, lrate=0.500, error=7.609\n",
      ">epoch=7, lrate=0.500, error=7.607\n",
      ">epoch=8, lrate=0.500, error=7.603\n",
      ">epoch=9, lrate=0.500, error=7.598\n",
      "[{'weights': [0.13419252906881313, 0.6923368171082648, 0.6685093822576059], 'output': 0.9999902467820663, 'delta': -5.765372818544188e-08}, {'weights': [0.46240374751192537, 1.4102818394645675, 0.3821172715309973], 'output': 0.9999999998529447, 'delta': -1.632755527499333e-11}]\n",
      "[{'weights': [0.021533153359603194, 0.40568379607469407, -0.48714155635881334], 'output': 0.12745797849574192, 'delta': -0.1253873552816308}, {'weights': [0.5455969310290191, 0.27389329155169523, 0.7867232615400346], 'output': 0.91979330532386, 'delta': 0.012350248941685238}, {'weights': [0.22216862855566874, -0.12257016233804553, -0.09932831853220148], 'output': -0.000535972708355148, 'delta': 0.0005359725543880132}, {'weights': [-0.06953233724130342, -0.07334194784061636, 0.14273677507154994], 'output': 0.0002736690846079082, 'delta': -0.00027366906411152564}, {'weights': [0.47002058159709414, -0.06892191212265894, -0.4004487999505751], 'output': -0.0012906036992035297, 'delta': 0.0012906015494992716}, {'weights': [-0.04787306589846221, 0.26842633608991295, -0.22049740431796536], 'output': -0.00011266770392526215, 'delta': 0.00011266770249505702}, {'weights': [0.06578588473607404, 0.05219661696616506, -0.11786049517037489], 'output': -0.00024273458761026045, 'delta': 0.00024273457330831912}, {'weights': [-0.14044416982737437, 0.016913403181891905, 0.12333112697742563], 'output': 0.0003965477398499839, 'delta': -0.00039654767749280824}, {'weights': [0.006687527367214494, 0.003213322927373816, -0.009889428033981533], 'output': -2.2714513571386874e-05, 'delta': 2.271451355966734e-05}, {'weights': [0.21174263645462024, 0.010811022517280555, -0.22223644994718236], 'output': -0.0006303009152971439, 'delta': 0.000630300664891673}]\n"
     ]
    }
   ],
   "source": [
    "# Test training backprop algorithm\n",
    "seed(1)\n",
    "dataset = [[0,2.7810836,2.550537003],\n",
    "\t[0,1.465489372,2.362125076],\n",
    "\t[0,3.396561688,4.400293529],\n",
    "\t[0,1.38807019,1.850220317],\n",
    "\t[0,3.06407232,3.005305973],\n",
    "\t[1,7.627531214,2.759262235],\n",
    "\t[1,5.332441248,2.088626775],\n",
    "\t[1,6.922596716,1.77106367],\n",
    "\t[1,8.675418651,-0.242068655],\n",
    "\t[1,7.673756466,3.508563011]]\n",
    "n_inputs = len(dataset[0]) - 1\n",
    "n_outputs = len(set([row[-1] for row in dataset]))\n",
    "network = initialize_network(n_inputs, 2, n_outputs)\n",
    "train_network(network, dataset, 0.5, 10, n_outputs)\n",
    "for layer in network:\n",
    "\tprint(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with a network\n",
    "def predict(network, row):\n",
    "\toutputs = forward_propagate(network, row)\n",
    "\treturn outputs.index(max(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=0, Got=1\n",
      "Expected=0, Got=1\n",
      "Expected=0, Got=1\n",
      "Expected=0, Got=1\n",
      "Expected=0, Got=1\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n"
     ]
    }
   ],
   "source": [
    "for row in dataset:\n",
    "\tprediction = predict(network, row)\n",
    "\tprint('Expected=%d, Got=%d' % (row[0], prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4.0000': 0,\n",
       " '3.0000': 1,\n",
       " '5.0000': 2,\n",
       " '1.0000': 3,\n",
       " '6.0000': 4,\n",
       " '0.0000': 5,\n",
       " '9.0000': 6,\n",
       " '2.0000': 7,\n",
       " '7.0000': 8,\n",
       " '8.0000': 9}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Backprop on the Seeds Dataset\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from random import random\n",
    "from csv import reader\n",
    "from math import exp\n",
    "\n",
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row[0].split())\n",
    "    return dataset\n",
    "\n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = float(row[column].strip())\n",
    "\n",
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = dict()\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup\n",
    "\n",
    "# Find the min and max values for each column\n",
    "def dataset_minmax(dataset):\n",
    "\tminmax = list()\n",
    "\tstats = [[min(column), max(column)] for column in zip(*dataset)]\n",
    "\treturn stats\n",
    "\n",
    "# Rescale dataset columns to the range 0-1\n",
    "def normalize_dataset(dataset, minmax):\n",
    "\tfor row in dataset:\n",
    "\t\tfor i in range(len(row)-1):\n",
    "\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "# load and prepare data\n",
    "train_filename = 'Digits/ZipDigits.train'\n",
    "test_filename = 'Digits/ZipDigits.test'\n",
    "train_dataset = load_csv(train_filename)\n",
    "for i in range(1, len(train_dataset[0])):\n",
    "    str_column_to_float(train_dataset, i)\n",
    "# # convert class column to integers\n",
    "str_column_to_int(train_dataset, 0)\n",
    "\n",
    "test_dataset = load_csv(test_filename)\n",
    "for i in range(1, len(test_dataset[0])):\n",
    "    str_column_to_float(test_dataset, i)\n",
    "# # convert class column to integers\n",
    "str_column_to_int(test_dataset, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = dataset_minmax(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_dataset(dataset, minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation Algorithm With Stochastic Gradient Descent\n",
    "def back_propagation(train, test, l_rate, n_epoch, n_hidden):\n",
    "\tn_inputs = len(train[0]) - 1\n",
    "\tn_outputs = len(set([row[-1] for row in train]))\n",
    "\tnetwork = initialize_network(n_inputs, n_hidden, n_outputs)\n",
    "\ttrain_network(network, train, l_rate, n_epoch, n_outputs)\n",
    "\tpredictions = list()\n",
    "\tfor row in test:\n",
    "\t\tprediction = predict(network, row)\n",
    "\t\tpredictions.append(prediction)\n",
    "\treturn(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(train_dataset, test_dataset, algorithm, n_folds, *args):\n",
    "\tfolds = cross_validation_split(dataset, n_folds)\n",
    "\tscores = list()\n",
    "\tfor fold in folds:\n",
    "\t\ttrain_set = list(folds)\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "\t\ttest_set = list()\n",
    "\t\tfor row in fold:\n",
    "\t\t\trow_copy = list(row)\n",
    "\t\t\ttest_set.append(row_copy)\n",
    "\t\t\trow_copy[-1] = None\n",
    "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
    "\t\tactual = [row[-1] for row in fold]\n",
    "\t\taccuracy = accuracy_metric(actual, predicted)\n",
    "\t\tscores.append(accuracy)\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "10\n",
      "7291\n",
      ">epoch=0, lrate=0.500, error=90515.468\n",
      ">epoch=1, lrate=0.500, error=76364.103\n",
      ">epoch=2, lrate=0.500, error=73472.026\n",
      ">epoch=3, lrate=0.500, error=70799.412\n"
     ]
    }
   ],
   "source": [
    "n_inputs = len(train_dataset[0]) - 1\n",
    "n_outputs = len(set([row[0] for row in train_dataset]))\n",
    "print(n_inputs)\n",
    "print(n_outputs)\n",
    "print(len(train_dataset))\n",
    "network = initialize_network(n_inputs, 100, n_outputs)\n",
    "train_network(network, train_dataset, 0.5, 10, n_outputs)\n",
    "for layer in network:\n",
    "\tprint(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
